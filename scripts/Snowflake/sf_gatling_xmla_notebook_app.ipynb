{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "setup"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "report_data = {}\n",
    "success = True\n",
    "\n",
    "#set the run_ids for the evaluation\n",
    "raw_runids = \"2025-11-25-GAVwLbJRq7, 2025-11-25-oJv5ed5Asn\" \n",
    "\n",
    "\n",
    "runids = [item.strip() for item in raw_runids.split(',')]\n",
    "runid_a= runids[0]\n",
    "runid_b= runids[1]\n",
    "\n",
    "#set the performance threshold for the evaluation\n",
    "perf_threshold_percent = 70\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "failed_queries"
   },
   "outputs": [],
   "source": [
    "statement = f\"\"\"\n",
    "select *\n",
    "from GATLING_XMLA_HEADERS\n",
    "where status = 'FAILED'\n",
    "and gatling_run_id in ('{runid_a}','{runid_b}')\n",
    "\"\"\"\n",
    "df = session.sql(statement).to_pandas()\n",
    "num_rows = df.shape[0]\n",
    "\n",
    "if(num_rows == 0):\n",
    "    report_data['Failed queries'] = f\"{num_rows} queries report as failed for run ids : {runid_a} and {runid_b}\"\n",
    "    report_data['Failed queries']\n",
    "    df.head(10)\n",
    "else:\n",
    "    success = success and False\n",
    "    report_data['Failed queries'] = f\"{num_rows} queries report as failed for run ids : {runid_a} and {runid_b}\"\n",
    "    report_data['Failed queries']\n",
    "    df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "inconsistent_failure_check"
   },
   "outputs": [],
   "source": [
    "statement = f\"\"\"\n",
    "SELECT\n",
    "    COALESCE(a.QUERY_HASH, b.QUERY_HASH) AS query_hash,\n",
    "    a.QUERY_NAME AS query_name_a,\n",
    "    a.STATUS AS status_a,\n",
    "    b.QUERY_NAME AS query_name_b,\n",
    "    b.STATUS AS status_b,\n",
    "    CASE\n",
    "        WHEN a.GATLING_RUN_ID IS NULL THEN 'Failed in B only (Query missing from A)'\n",
    "        WHEN b.GATLING_RUN_ID IS NULL THEN 'Failed in A only (Query missing from B)'\n",
    "        WHEN a.STATUS = 'FAILED' AND b.STATUS != 'FAILED' THEN 'Failed in A only'\n",
    "        WHEN a.STATUS != 'FAILED' AND b.STATUS = 'FAILED' THEN 'Failed in B only'\n",
    "        ELSE 'Status Mismatch'\n",
    "    END AS failure_type\n",
    "FROM\n",
    "    (SELECT * FROM GATLING_XMLA_HEADERS WHERE GATLING_RUN_ID = '{runid_a}') a\n",
    "FULL OUTER JOIN\n",
    "    (SELECT * FROM GATLING_XMLA_HEADERS WHERE GATLING_RUN_ID = '{runid_b}') b\n",
    "ON\n",
    "    a.QUERY_HASH = b.QUERY_HASH\n",
    "WHERE\n",
    "    (a.STATUS IS DISTINCT FROM b.STATUS) -- Status is different (e.g., FAILED vs OK, or one is NULL)\n",
    "    OR (a.GATLING_RUN_ID IS NULL AND b.GATLING_RUN_ID IS NOT NULL) -- Query only exists in B\n",
    "    OR (b.GATLING_RUN_ID IS NULL AND a.GATLING_RUN_ID IS NOT NULL); -- Query only exists in A\n",
    "\"\"\"\n",
    "\n",
    "df = session.sql(statement).to_pandas()\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "\n",
    "if (num_rows == 0):\n",
    "    report_data['Failed query details'] = f\"If query failures exist they are consistent between runs for run ids : {runid_a} and {runid_b}\"\n",
    "    report_data['Failed query details']\n",
    "else:\n",
    "    success = success and False\n",
    "    report_data['Failed query details'] = f\"There are {num_rows} query failure differences between query runs for run ids : {runid_a} and {runid_b}\"\n",
    "    report_data['Failed query details']\n",
    "    df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92db823-9644-4372-a401-c0ced267e5a9",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "queries_by_model_validation"
   },
   "outputs": [],
   "source": [
    "statement = f\"\"\"\n",
    "Select gatling_run_id, model, count(query_name) as num_queries \n",
    "from gatling_xmla_headers\n",
    "where gatling_run_id in ('{runid_a}', '{runid_b}')\n",
    "group by 1, 2\n",
    "\"\"\"\n",
    "\n",
    "df = session.sql(statement).to_pandas()\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "assert num_rows == 2, f\"Expected 2 rows found {num_rows} Check the values set for runid_a and runid_b\"\n",
    "\n",
    "column_name = 'NUM_QUERIES'\n",
    "\n",
    "# Get the value from the first row to compare against\n",
    "expected_value = df[column_name].iloc[0]\n",
    "\n",
    "are_all_same = (df[column_name] == expected_value).all()\n",
    "\n",
    "if(are_all_same):\n",
    "    report_data['Queries by model'] = f\"✅ Validated number of query result set rows by model: {expected_value}\"\n",
    "    report_data['Queries by model']\n",
    "else:\n",
    "    success = success and False\n",
    "    report_data['Queries by model'] = f\"Result sets contain inconsistent number of rows.\"\n",
    "    report_data['Queries by model']\n",
    "    df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf2661-b0f2-442b-9002-397e310312ba",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "responses_by_model_validation"
   },
   "outputs": [],
   "source": [
    "statement = f\"\"\"\n",
    "Select gatling_run_id, model, count(query_name) as num_queries \n",
    "from gatling_xmla_responses\n",
    "where gatling_run_id in ('{runid_a}', '{runid_b}')\n",
    "group by 1, 2\n",
    "\"\"\"\n",
    "df = session.sql(statement).to_pandas()\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "assert num_rows == 2, f\"Expected 2 rows found {num_rows}\"\n",
    "\n",
    "column_name = 'NUM_QUERIES'\n",
    "\n",
    "# Get the value from the first row to compare against\n",
    "expected_value = df[column_name].iloc[0]\n",
    "\n",
    "are_all_same = (df[column_name] == expected_value).all()\n",
    "\n",
    "if(are_all_same):\n",
    "    report_data['Details by model'] = f\"✅ Validated numer of detail records by model: {expected_value}\"\n",
    "    report_data['Details by model']\n",
    "else:\n",
    "    success = success and False\n",
    "    report_data['Details by model'] = f\"Column '{column_name}' contains inconsistent values.\"\n",
    "    report_data['Details by model']\n",
    "    df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616ffd0c-6431-4562-97ee-a4d71aa0c1ed",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "results_match_validation"
   },
   "outputs": [],
   "source": [
    "results_matching_query = f\"\"\"\n",
    "with\n",
    "    a as (\n",
    "        select\n",
    "            model as model_name,\n",
    "            query_name,\n",
    "            atscale_query_id,\n",
    "            query_hash,\n",
    "            status,\n",
    "            soap_body_hash\n",
    "        from gatling_xmla_responses\n",
    "        where gatling_run_id = '{runid_a}'\n",
    "    ),\n",
    "    b as (\n",
    "        select\n",
    "            model as model_name,\n",
    "            query_name,\n",
    "            atscale_query_id,\n",
    "            query_hash,\n",
    "            status,\n",
    "            soap_body_hash\n",
    "        from gatling_xmla_responses\n",
    "        where gatling_run_id = '{runid_b}'\n",
    "    )\n",
    "select * from a where not exists (select soap_body_hash from b where a.soap_body_hash = b.soap_body_hash)\n",
    "    UNION\n",
    "    select * from b where not exists (select soap_body_hash from a where a.soap_body_hash = b.soap_body_hash)\n",
    "\"\"\"\n",
    "\n",
    "df = session.sql(results_matching_query)\n",
    "\n",
    "# Get the row count\n",
    "row_count = df.count()\n",
    "\n",
    "if(row_count == 0):\n",
    "    report_data['Results Matching Test'] = f\"✅ Validated results match for run ids : {runid_a} and {runid_b}\"\n",
    "    report_data['Results Matching Test']\n",
    "else:\n",
    "    success = success and False\n",
    "    report_data['Results Matching Test'] = f\"Failed there are {row_count} records where results do not match as expected for run ids: {runid_a} and {runid_b}\"\n",
    "    report_data['Results Matching Test']\n",
    "    df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0529a85-4888-4744-922a-e9e1b96e58d2",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "performance_validation"
   },
   "outputs": [],
   "source": [
    "performance_evaluation_query = f\"\"\"\n",
    "with\n",
    "    a as (\n",
    "        select\n",
    "            model as model_name,\n",
    "            query_name,\n",
    "            atscale_query_id,\n",
    "            query_hash,\n",
    "            gatling_session_id,\n",
    "            status,\n",
    "            duration_ms\n",
    "        from gatling_xmla_headers\n",
    "        where gatling_run_id = '{runid_a}'\n",
    "    ),\n",
    "    b as (\n",
    "        select\n",
    "            model as model_name,\n",
    "            query_name,\n",
    "            atscale_query_id,\n",
    "            query_hash,\n",
    "            gatling_session_id,\n",
    "            status,\n",
    "            duration_ms\n",
    "        from gatling_xmla_headers\n",
    "        where gatling_run_id = '{runid_b}'\n",
    "    ),\n",
    "    joined as (\n",
    "        select\n",
    "            a.model_name,\n",
    "            a.query_name,\n",
    "            a.atscale_query_id,\n",
    "            a.query_hash,\n",
    "            a.gatling_session_id,\n",
    "            a.status,\n",
    "            a.duration_ms as duration_a,\n",
    "            b.duration_ms as duration_b,\n",
    "            round(((b.duration_ms - a.duration_ms) / nullif(a.duration_ms, 0)) * 100, 2) as pct_diff\n",
    "        from a\n",
    "            join b\n",
    "            on  a.model_name         = b.model_name\n",
    "            and a.query_hash         = b.query_hash\n",
    "            and a.gatling_session_id = b.gatling_session_id\n",
    "    )\n",
    "\n",
    "select\n",
    "    model_name,\n",
    "    query_name,\n",
    "    atscale_query_id,\n",
    "    query_hash,\n",
    "    gatling_session_id as simulation_user,\n",
    "    status,\n",
    "    duration_a,\n",
    "    duration_b,\n",
    "    pct_diff,\n",
    "    case\n",
    "        when pct_diff > 0 then 'SLOWER'\n",
    "        when pct_diff < 0 then 'FASTER'\n",
    "        else 'SAME'\n",
    "        end as perf_change\n",
    "from joined\n",
    "where abs(pct_diff) >= {perf_threshold_percent}\n",
    "order by abs(pct_diff) desc, query_hash\n",
    "\"\"\"\n",
    "\n",
    "df = session.sql(performance_evaluation_query)\n",
    "\n",
    "# Get the row count\n",
    "row_count = df.count()\n",
    "\n",
    "if(row_count == 0):\n",
    "    report_data['Performance Evaluation Test'] = f\"✅ Validated performance results for run ids: {runid_a} and {runid_b} are within {perf_threshold_percent} percent\"\n",
    "    report_data['Performance Evaluation Test']\n",
    "else:\n",
    "    success = success and False\n",
    "    report_data['Performance Evaluation Test'] = f\"Failed performance results for for run ids: {runid_a} and {runid_b} {row_count} records are not within {perf_threshold_percent} percent as expected\"\n",
    "    report_data['Performance Evaluation Test']\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e1a91-a95a-4692-b2b0-006ff539b4ea",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "report_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eaf9bf-8c80-418f-b286-1ff6a1a93753",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "if success:\n",
    "    assert(True)\n",
    "    print(\"All tests passed\")\n",
    "else:\n",
    "    print(\"Check for test failures\")\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d0506-e5e1-4ffc-b312-d27c23e907dc",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d4fb0-b855-428f-9de6-6180268fad18",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "steve.hall@atscale.com",
   "authorId": "7749513225674",
   "authorName": "STEVE_HALL",
   "lastEditTime": 1764105069123,
   "notebookId": "yd6kbspvzcv3jmfpaprv",
   "sessionId": "68e37d94-eca3-4ec0-a5e7-88af6f781995"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
